{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b388876f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens in Prompt: 68\n",
      "number of tokesn in Output 47\n",
      "Number of tokens in Prompt: 68\n",
      "number of tokesn in Output 76\n",
      "Number of tokens in Prompt: 68\n",
      "number of tokesn in Output 105\n",
      "Number of tokens in Prompt: 68\n",
      "number of tokesn in Output 83\n",
      "Number of tokens in Prompt: 84\n",
      "number of tokesn in Output 150\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Hello! ðŸ‘‹ How can I assist you today?',\n",
       " 'Goodbye! If you ever need anything else, just let me know. Have a great day!',\n",
       " \"Got it! If thereâ€™s anything else youâ€™d like to discuss or ask about, just let me know. I'm here to help.\",\n",
       " 'Great! How can I assist you today?',\n",
       " 'Iâ€™m not sure I completely understand what youâ€™re askingâ€”could you clarify a bit? Here are a few possible ways to interpret the question, and what the answer would look like for each:\\n\\n']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from google import genai\n",
    "from google.genai import types\n",
    "import os\n",
    "from typing import List\n",
    "\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = '/scratch/asing725/CSE336/privacy_qa/prompt-qwen-3-9adf83a178fb.json'\n",
    "PROJECT_ID = \"prompt-qwen-3\"\n",
    "LOCATION = \"global\"\n",
    "\n",
    "def generate_single(prompt: str, client: genai.Client, model: str, config: types.GenerateContentConfig) -> str:\n",
    "    \"\"\"Generate response for a single prompt (non-streaming)\"\"\"\n",
    "    contents = [\n",
    "        types.Content(\n",
    "            role=\"user\",\n",
    "            parts=[types.Part(text=prompt)]\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    response = client.models.generate_content(\n",
    "        model=model,\n",
    "        contents=contents,\n",
    "        config=config,\n",
    "    )\n",
    "    \n",
    "    # Get full response without streaming\n",
    "    return response\n",
    "\n",
    "\n",
    "def get_batch_results(prompts: List, max_tokens: int, temperature: float, model_name: str) -> List[str]:\n",
    "    client = genai.Client(\n",
    "        vertexai=True,\n",
    "        location=LOCATION\n",
    "    )\n",
    "\n",
    "    config = types.GenerateContentConfig(\n",
    "        temperature=temperature,\n",
    "        max_output_tokens=max_tokens,\n",
    "    )\n",
    "    results = []\n",
    "    for entry in prompts:\n",
    "        single_response = generate_single(entry, client, model_name, config)\n",
    "        usage = single_response.usage_metadata\n",
    "        print(\"Number of tokens in Prompt:\", (usage.prompt_token_count))\n",
    "        print(\"number of tokesn in Output\",usage.candidates_token_count)\n",
    "        results.append(single_response.text)\n",
    "\n",
    "    return results\n",
    "\n",
    "# model = \"gemini-2.0-flash-001\"\n",
    "# model = \"openai/gpt-oss-120b-maas\"\n",
    "# model = \"qwen/qwen3-next-80b-a3b-instruct-maas\"\n",
    "get_batch_results(['Hi','Bye','No','Yes',\"How many people like icecream with one piece and goku in code geass?\"],150,0.1,'openai/gpt-oss-120b-maas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1720c3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "qwen/qwen3-next-80b-a3b-instruct-maas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ea9262f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/asing725/.conda/envs/ranker/lib/python3.10/site-packages/torch/cuda/__init__.py:827: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11.2\n"
     ]
    }
   ],
   "source": [
    "import vllm; print(vllm.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fcd10786",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 01-01 17:22:09 __init__.py:194] No platform detected, vLLM is running on UnspecifiedPlatform\n",
      "0.7.2\n"
     ]
    }
   ],
   "source": [
    "import vllm; print(vllm.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93762bc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f553ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3a0040b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'**AI**, short for **Artificial Intelligence**, refers to the simulation of human intelligence in machines that are programmed to think, learn, reason, perceive, solve problems, make decisions, and even understand and generate human language.\\n\\n### In simpler terms:\\nAI enables computers and machines to perform tasks that normally require human intelligence â€” like recognizing speech, identifying objects in images, translating languages, playing chess, recommending movies, or driving a car â€” without being explicitly programmed for each specific task.\\n\\n### Key Areas of'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d119c25",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ranker",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
